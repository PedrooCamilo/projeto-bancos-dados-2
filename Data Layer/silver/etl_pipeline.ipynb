{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2326fa6",
   "metadata": {},
   "source": [
    "# üé¨ ETL Pipeline - RAW ‚Üí SILVER (Lakehouse)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Sum√°rio\n",
    "\n",
    "Este notebook implementa o **pipeline ETL completo** que transforma dados brutos (RAW) em dados curados (SILVER) no lakehouse.\n",
    "\n",
    "### Etapas do Pipeline:\n",
    "\n",
    "1. **üì• EXTRA√á√ÉO (Extract)**: Leitura dos arquivos CSV da camada RAW\n",
    "2. **üîÑ TRANSFORMA√á√ÉO (Transform)**: Limpeza, mesclagem e enriquecimento dos dados\n",
    "3. **üì§ CARGA (Load)**: Inser√ß√£o no banco de dados MySQL (Lakehouse)\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Objetivo\n",
    "\n",
    "Criar um **lakehouse populado** com dados de filmes e avalia√ß√µes, pronto para an√°lises e consultas SQL.\n",
    "\n",
    "### üìä Dados de Entrada (RAW):\n",
    "- `movies_metadata.csv`: ~45K filmes\n",
    "- `credits.csv`: ~45K registros de elenco/equipe\n",
    "- `keywords.csv`: ~46K palavras-chave\n",
    "- `ratings_small.csv`: ~100K avalia√ß√µes\n",
    "\n",
    "### üíæ Dados de Sa√≠da (SILVER):\n",
    "- Tabela `movies`: 45.433 filmes\n",
    "- Tabela `ratings`: 44.989 avalia√ß√µes v√°lidas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6808a57d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì¶ 1. Importa√ß√£o de Bibliotecas\n",
    "\n",
    "Carregamento das bibliotecas necess√°rias para o ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239f6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.pool import NullPool\n",
    "import mysql.connector\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")\n",
    "print(f\"üìå Pandas vers√£o: {pd.__version__}\")\n",
    "print(f\"üìå NumPy vers√£o: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b5b4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß 2. Configura√ß√£o da Conex√£o com o Banco\n",
    "\n",
    "Conex√£o com o **MySQL Lakehouse** usando SQLAlchemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bdaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√µes do banco de dados\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',  # ou 'db' se estiver dentro do container\n",
    "    'port': 3306,\n",
    "    'database': 'movies_db',\n",
    "    'user': 'app_user',\n",
    "    'password': 'app_password'\n",
    "}\n",
    "\n",
    "# String de conex√£o\n",
    "connection_string = (\n",
    "    f\"mysql+mysqlconnector://{DB_CONFIG['user']}:{DB_CONFIG['password']}\"\n",
    "    f\"@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    ")\n",
    "\n",
    "# Criar engine\n",
    "engine = create_engine(\n",
    "    connection_string,\n",
    "    poolclass=NullPool,\n",
    "    echo=False\n",
    ")\n",
    "\n",
    "# Testar conex√£o\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT 'Conex√£o OK!' as status\"))\n",
    "        print(\"‚úÖ\", result.fetchone()[0])\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro na conex√£o: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313c7b4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì• 3. FASE 1: EXTRA√á√ÉO (Extract)\n",
    "\n",
    "Leitura dos arquivos CSV da camada RAW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6500e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos dos arquivos\n",
    "DATA_PATH = '../raw/dados_brutos/'\n",
    "\n",
    "print(\"üì• Iniciando extra√ß√£o dos dados...\\n\")\n",
    "\n",
    "# 1. Movies Metadata\n",
    "print(\"üìÑ Carregando movies_metadata.csv...\")\n",
    "df_movies = pd.read_csv(\n",
    "    f'{DATA_PATH}movies_metadata.csv',\n",
    "    low_memory=False,\n",
    "    dtype={'id': str}\n",
    ")\n",
    "print(f\"   ‚úì {len(df_movies):,} filmes carregados\")\n",
    "\n",
    "# 2. Credits (elenco e equipe)\n",
    "print(\"üìÑ Carregando credits.csv...\")\n",
    "df_credits = pd.read_csv(\n",
    "    f'{DATA_PATH}credits.csv',\n",
    "    dtype={'id': str}\n",
    ")\n",
    "print(f\"   ‚úì {len(df_credits):,} registros de cr√©ditos carregados\")\n",
    "\n",
    "# 3. Keywords\n",
    "print(\"üìÑ Carregando keywords.csv...\")\n",
    "df_keywords = pd.read_csv(\n",
    "    f'{DATA_PATH}keywords.csv',\n",
    "    dtype={'id': str}\n",
    ")\n",
    "print(f\"   ‚úì {len(df_keywords):,} registros de palavras-chave carregados\")\n",
    "\n",
    "# 4. Ratings\n",
    "print(\"üìÑ Carregando ratings_small.csv...\")\n",
    "df_ratings = pd.read_csv(\n",
    "    f'{DATA_PATH}ratings_small.csv'\n",
    ")\n",
    "print(f\"   ‚úì {len(df_ratings):,} avalia√ß√µes carregadas\")\n",
    "\n",
    "print(\"\\n‚úÖ Extra√ß√£o conclu√≠da com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883cf68f",
   "metadata": {},
   "source": [
    "### üìä Visualiza√ß√£o dos Dados Brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Primeiras linhas - Movies:\")\n",
    "display(df_movies.head(3))\n",
    "\n",
    "print(\"\\nüîç Primeiras linhas - Ratings:\")\n",
    "display(df_ratings.head(3))\n",
    "\n",
    "print(\"\\nüìà Informa√ß√µes dos DataFrames:\")\n",
    "print(f\"Movies: {df_movies.shape}\")\n",
    "print(f\"Credits: {df_credits.shape}\")\n",
    "print(f\"Keywords: {df_keywords.shape}\")\n",
    "print(f\"Ratings: {df_ratings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9787a25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÑ 4. FASE 2: TRANSFORMA√á√ÉO (Transform)\n",
    "\n",
    "Aplica√ß√£o das transforma√ß√µes e limpezas necess√°rias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec9e4d4",
   "metadata": {},
   "source": [
    "### üßπ Etapa 1: Limpeza de IDs Inv√°lidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15adaf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üßπ Etapa 1: Limpeza de IDs inv√°lidos\\n\")\n",
    "\n",
    "# Remover registros com ID inv√°lido (n√£o num√©rico)\n",
    "initial_count = len(df_movies)\n",
    "\n",
    "df_movies = df_movies[pd.to_numeric(df_movies['id'], errors='coerce').notna()]\n",
    "df_credits = df_credits[pd.to_numeric(df_credits['id'], errors='coerce').notna()]\n",
    "df_keywords = df_keywords[pd.to_numeric(df_keywords['id'], errors='coerce').notna()]\n",
    "\n",
    "removed = initial_count - len(df_movies)\n",
    "print(f\"   ‚úì {removed} registros com ID inv√°lido removidos\")\n",
    "print(f\"   ‚úì {len(df_movies):,} filmes restantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b75c0",
   "metadata": {},
   "source": [
    "### üîó Etapa 2: Mesclagem dos DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ee07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîó Etapa 2: Mesclagem dos DataFrames\\n\")\n",
    "\n",
    "# Mesclar movies com credits\n",
    "df_merged = df_movies.merge(df_credits, on='id', how='left')\n",
    "print(f\"   ‚úì Ap√≥s merge com credits: {df_merged.shape}\")\n",
    "\n",
    "# Mesclar com keywords\n",
    "df_merged = df_merged.merge(df_keywords, on='id', how='left')\n",
    "print(f\"   ‚úì Ap√≥s merge com keywords: {df_merged.shape}\")\n",
    "\n",
    "# Remover duplicatas\n",
    "initial = len(df_merged)\n",
    "df_merged = df_merged.drop_duplicates(subset=['id'], keep='first')\n",
    "duplicates = initial - len(df_merged)\n",
    "print(f\"   ‚úì {duplicates:,} duplicatas removidas\")\n",
    "print(f\"   ‚úì DataFrame final: {df_merged.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f312dc6e",
   "metadata": {},
   "source": [
    "### üî¢ Etapa 3: Convers√£o de Tipos de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4093c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¢ Etapa 3: Convers√£o de tipos de dados\\n\")\n",
    "\n",
    "# Converter ID para inteiro\n",
    "df_merged['id'] = pd.to_numeric(df_merged['id'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Converter colunas num√©ricas\n",
    "numeric_cols = ['budget', 'revenue', 'runtime', 'popularity', 'vote_average', 'vote_count']\n",
    "for col in numeric_cols:\n",
    "    if col in df_merged.columns:\n",
    "        df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')\n",
    "\n",
    "# Converter data de lan√ßamento\n",
    "df_merged['release_date'] = pd.to_datetime(df_merged['release_date'], errors='coerce')\n",
    "\n",
    "print(\"   ‚úì Tipos de dados convertidos\")\n",
    "print(f\"\\nüìä Tipos das principais colunas:\")\n",
    "print(df_merged[['id', 'budget', 'revenue', 'runtime', 'release_date']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15e30c1",
   "metadata": {},
   "source": [
    "### üì¶ Etapa 4: Extra√ß√£o de Dados JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f229dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Etapa 4: Extra√ß√£o de dados JSON\\n\")\n",
    "\n",
    "def extract_names_from_json(json_str, key='name', max_items=5, separator=', '):\n",
    "    \"\"\"Extrai nomes de uma string JSON.\"\"\"\n",
    "    if pd.isna(json_str) or json_str == '':\n",
    "        return ''\n",
    "    try:\n",
    "        data = json.loads(json_str.replace(\"'\", '\"'))\n",
    "        if isinstance(data, list):\n",
    "            names = [item.get(key, '') for item in data[:max_items] if isinstance(item, dict)]\n",
    "            return separator.join(filter(None, names))\n",
    "        return ''\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "# Extrair g√™neros\n",
    "print(\"   üé≠ Extraindo g√™neros...\")\n",
    "df_merged['genres'] = df_merged['genres'].apply(extract_names_from_json)\n",
    "\n",
    "# Extrair elenco (cast) - top 5\n",
    "print(\"   üé¨ Extraindo elenco principal...\")\n",
    "df_merged['cast'] = df_merged['cast'].apply(extract_names_from_json)\n",
    "\n",
    "# Extrair equipe (crew) - diretores\n",
    "print(\"   üé• Extraindo equipe t√©cnica...\")\n",
    "df_merged['crew'] = df_merged['crew'].apply(extract_names_from_json)\n",
    "\n",
    "# Extrair keywords\n",
    "print(\"   üîë Extraindo palavras-chave...\")\n",
    "df_merged['keywords'] = df_merged['keywords'].apply(extract_names_from_json)\n",
    "\n",
    "# Extrair production companies\n",
    "print(\"   üè¢ Extraindo produtoras...\")\n",
    "df_merged['production_companies'] = df_merged['production_companies'].apply(extract_names_from_json)\n",
    "\n",
    "# Extrair production countries\n",
    "print(\"   üåç Extraindo pa√≠ses de produ√ß√£o...\")\n",
    "df_merged['production_countries'] = df_merged['production_countries'].apply(extract_names_from_json)\n",
    "\n",
    "# Extrair spoken languages\n",
    "print(\"   üó£Ô∏è  Extraindo idiomas...\")\n",
    "df_merged['spoken_languages'] = df_merged['spoken_languages'].apply(extract_names_from_json)\n",
    "\n",
    "# Extrair belongs_to_collection\n",
    "print(\"   üìö Extraindo cole√ß√µes...\")\n",
    "df_merged['belongs_to_collection'] = df_merged['belongs_to_collection'].apply(\n",
    "    lambda x: extract_names_from_json(x, key='name', max_items=1) if pd.notna(x) else ''\n",
    ")\n",
    "\n",
    "print(\"\\n   ‚úì Dados JSON extra√≠dos e processados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7becae",
   "metadata": {},
   "source": [
    "### ‚úÇÔ∏è Etapa 5: Sele√ß√£o de Colunas Finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ad111",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úÇÔ∏è Etapa 5: Sele√ß√£o de colunas finais\\n\")\n",
    "\n",
    "# Colunas para a tabela MOVIES\n",
    "movies_columns = [\n",
    "    'id', 'title', 'overview', 'release_date',\n",
    "    'budget', 'revenue', 'runtime', 'popularity',\n",
    "    'status', 'tagline', 'vote_average', 'vote_count',\n",
    "    'imdb_id', 'original_language',\n",
    "    'genres', 'production_companies', 'production_countries',\n",
    "    'spoken_languages', 'belongs_to_collection'\n",
    "]\n",
    "\n",
    "df_movies_final = df_merged[movies_columns].copy()\n",
    "\n",
    "# Substituir valores vazios por string vazia\n",
    "text_columns = ['overview', 'tagline', 'status', 'imdb_id', 'original_language',\n",
    "                'genres', 'production_companies', 'production_countries',\n",
    "                'spoken_languages', 'belongs_to_collection']\n",
    "\n",
    "for col in text_columns:\n",
    "    df_movies_final[col] = df_movies_final[col].fillna('').astype(str)\n",
    "\n",
    "print(f\"   ‚úì DataFrame MOVIES preparado: {df_movies_final.shape}\")\n",
    "print(f\"   ‚úì Colunas: {len(movies_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647d0b6",
   "metadata": {},
   "source": [
    "### üåü Etapa 6: Transforma√ß√£o da Tabela RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üåü Etapa 6: Transforma√ß√£o da tabela RATINGS\\n\")\n",
    "\n",
    "# Renomear colunas\n",
    "df_ratings_final = df_ratings.rename(columns={\n",
    "    'userId': 'user_id',\n",
    "    'movieId': 'movie_id',\n",
    "    'timestamp': 'rating_timestamp'\n",
    "})\n",
    "\n",
    "# Converter timestamp UNIX para datetime\n",
    "df_ratings_final['rating_timestamp'] = pd.to_datetime(\n",
    "    df_ratings_final['rating_timestamp'], \n",
    "    unit='s'\n",
    ")\n",
    "\n",
    "# Remover avalia√ß√µes de filmes que n√£o existem no dataset final\n",
    "valid_movie_ids = set(df_movies_final['id'].dropna())\n",
    "initial_ratings = len(df_ratings_final)\n",
    "df_ratings_final = df_ratings_final[df_ratings_final['movie_id'].isin(valid_movie_ids)]\n",
    "removed_ratings = initial_ratings - len(df_ratings_final)\n",
    "\n",
    "print(f\"   ‚úì {removed_ratings:,} avalia√ß√µes de filmes inexistentes removidas\")\n",
    "print(f\"   ‚úì {len(df_ratings_final):,} avalia√ß√µes v√°lidas\")\n",
    "\n",
    "# Estat√≠sticas\n",
    "print(f\"\\nüìä Estat√≠sticas das avalia√ß√µes:\")\n",
    "print(f\"   ‚Ä¢ Usu√°rios √∫nicos: {df_ratings_final['user_id'].nunique():,}\")\n",
    "print(f\"   ‚Ä¢ Filmes avaliados: {df_ratings_final['movie_id'].nunique():,}\")\n",
    "print(f\"   ‚Ä¢ Nota m√©dia: {df_ratings_final['rating'].mean():.2f}\")\n",
    "print(f\"   ‚Ä¢ Per√≠odo: {df_ratings_final['rating_timestamp'].min()} a {df_ratings_final['rating_timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a3c5f2",
   "metadata": {},
   "source": [
    "### ‚úÖ Resumo da Transforma√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5e256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ TRANSFORMA√á√ÉO CONCLU√çDA COM SUCESSO!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä Resumo Final:\")\n",
    "print(f\"   ‚Ä¢ Filmes processados: {len(df_movies_final):,}\")\n",
    "print(f\"   ‚Ä¢ Avalia√ß√µes processadas: {len(df_ratings_final):,}\")\n",
    "print(f\"   ‚Ä¢ Colunas na tabela MOVIES: {len(df_movies_final.columns)}\")\n",
    "print(f\"   ‚Ä¢ Colunas na tabela RATINGS: {len(df_ratings_final.columns)}\")\n",
    "\n",
    "print(f\"\\nüîç Amostra dos dados transformados (MOVIES):\")\n",
    "display(df_movies_final[['id', 'title', 'genres', 'release_date', 'budget', 'revenue']].head(3))\n",
    "\n",
    "print(f\"\\nüîç Amostra dos dados transformados (RATINGS):\")\n",
    "display(df_ratings_final.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1003d2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì§ 5. FASE 3: CARGA (Load)\n",
    "\n",
    "Inser√ß√£o dos dados no banco de dados MySQL (Lakehouse)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70165b3f",
   "metadata": {},
   "source": [
    "### üßπ Limpeza das Tabelas Existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca99a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üßπ Limpando tabelas existentes...\\n\")\n",
    "\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        # Desabilitar foreign key checks temporariamente\n",
    "        conn.execute(text(\"SET FOREIGN_KEY_CHECKS = 0\"))\n",
    "        \n",
    "        # Truncar tabelas\n",
    "        conn.execute(text(\"TRUNCATE TABLE ratings\"))\n",
    "        conn.execute(text(\"TRUNCATE TABLE movies\"))\n",
    "        \n",
    "        # Reabilitar foreign key checks\n",
    "        conn.execute(text(\"SET FOREIGN_KEY_CHECKS = 1\"))\n",
    "        \n",
    "        conn.commit()\n",
    "    \n",
    "    print(\"   ‚úì Tabelas limpas com sucesso\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è  Aviso: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1f82b",
   "metadata": {},
   "source": [
    "### üì• Carregamento da Tabela MOVIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüì• Carregando tabela MOVIES...\\n\")\n",
    "\n",
    "try:\n",
    "    # Inserir dados em chunks para melhor performance\n",
    "    chunk_size = 1000\n",
    "    total_chunks = (len(df_movies_final) // chunk_size) + 1\n",
    "    \n",
    "    for i, chunk in enumerate(range(0, len(df_movies_final), chunk_size), 1):\n",
    "        df_chunk = df_movies_final.iloc[chunk:chunk + chunk_size]\n",
    "        df_chunk.to_sql(\n",
    "            name='movies',\n",
    "            con=engine,\n",
    "            if_exists='append',\n",
    "            index=False,\n",
    "            method='multi',\n",
    "            chunksize=500\n",
    "        )\n",
    "        print(f\"   ‚è≥ Progresso: {i}/{total_chunks} chunks ({(i/total_chunks)*100:.1f}%)\", end='\\r')\n",
    "    \n",
    "    print(f\"\\n   ‚úÖ {len(df_movies_final):,} filmes carregados com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n   ‚ùå Erro ao carregar MOVIES: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a5d48e",
   "metadata": {},
   "source": [
    "### üì• Carregamento da Tabela RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüì• Carregando tabela RATINGS...\\n\")\n",
    "\n",
    "try:\n",
    "    # Inserir dados em chunks\n",
    "    chunk_size = 1000\n",
    "    total_chunks = (len(df_ratings_final) // chunk_size) + 1\n",
    "    \n",
    "    for i, chunk in enumerate(range(0, len(df_ratings_final), chunk_size), 1):\n",
    "        df_chunk = df_ratings_final.iloc[chunk:chunk + chunk_size]\n",
    "        df_chunk.to_sql(\n",
    "            name='ratings',\n",
    "            con=engine,\n",
    "            if_exists='append',\n",
    "            index=False,\n",
    "            method='multi',\n",
    "            chunksize=500\n",
    "        )\n",
    "        print(f\"   ‚è≥ Progresso: {i}/{total_chunks} chunks ({(i/total_chunks)*100:.1f}%)\", end='\\r')\n",
    "    \n",
    "    print(f\"\\n   ‚úÖ {len(df_ratings_final):,} avalia√ß√µes carregadas com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n   ‚ùå Erro ao carregar RATINGS: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d7be73",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ 6. VALIDA√á√ÉO E ESTAT√çSTICAS FINAIS\n",
    "\n",
    "Verifica√ß√£o dos dados carregados no lakehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd630b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ PIPELINE ETL CONCLU√çDO COM SUCESSO!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verificar contadores no banco\n",
    "print(\"\\nüìä Verificando dados no lakehouse...\\n\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # Contar filmes\n",
    "    result = conn.execute(text(\"SELECT COUNT(*) FROM movies\"))\n",
    "    movies_count = result.fetchone()[0]\n",
    "    print(f\"   üé¨ Filmes na tabela MOVIES: {movies_count:,}\")\n",
    "    \n",
    "    # Contar avalia√ß√µes\n",
    "    result = conn.execute(text(\"SELECT COUNT(*) FROM ratings\"))\n",
    "    ratings_count = result.fetchone()[0]\n",
    "    print(f\"   ‚≠ê Avalia√ß√µes na tabela RATINGS: {ratings_count:,}\")\n",
    "    \n",
    "    # Usu√°rios √∫nicos\n",
    "    result = conn.execute(text(\"SELECT COUNT(DISTINCT user_id) FROM ratings\"))\n",
    "    users_count = result.fetchone()[0]\n",
    "    print(f\"   üë• Usu√°rios √∫nicos: {users_count:,}\")\n",
    "    \n",
    "    # Estat√≠sticas gerais\n",
    "    print(\"\\nüìà Executando procedure de estat√≠sticas...\\n\")\n",
    "    result = conn.execute(text(\"CALL sp_database_stats()\"))\n",
    "    stats = result.fetchall()\n",
    "    \n",
    "    for row in stats:\n",
    "        print(f\"\\n   üìä Tabela: {row[0]}\")\n",
    "        print(f\"      ‚Ä¢ Total de registros: {row[1]:,}\")\n",
    "        print(f\"      ‚Ä¢ IDs √∫nicos: {row[2]:,}\")\n",
    "        print(f\"      ‚Ä¢ Data mais antiga: {row[3]}\")\n",
    "        print(f\"      ‚Ä¢ Data mais recente: {row[4]}\")\n",
    "        if row[5] is not None:\n",
    "            print(f\"      ‚Ä¢ Or√ßamento m√©dio: ${row[5]:,.2f}\")\n",
    "        if row[6] is not None:\n",
    "            print(f\"      ‚Ä¢ Receita m√©dia: ${row[6]:,.2f}\")\n",
    "        if row[7] is not None:\n",
    "            print(f\"      ‚Ä¢ Avalia√ß√£o m√©dia: {row[7]:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ LAKEHOUSE POPULADO E PRONTO PARA USO!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d2a17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç 7. CONSULTAS DE EXEMPLO\n",
    "\n",
    "Demonstra√ß√£o de consultas SQL usando as views criadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d139f9",
   "metadata": {},
   "source": [
    "### üìä View: Filmes com Estat√≠sticas Agregadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0331cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 filmes mais lucrativos\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    title,\n",
    "    genres,\n",
    "    YEAR(release_date) as ano,\n",
    "    budget,\n",
    "    revenue,\n",
    "    roi_percentage,\n",
    "    user_avg_rating,\n",
    "    user_ratings_count\n",
    "FROM v_movies_with_stats\n",
    "WHERE revenue > 0 AND budget > 0\n",
    "ORDER BY revenue DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df_top_revenue = pd.read_sql(query, engine)\n",
    "print(\"üèÜ Top 10 Filmes Mais Lucrativos:\\n\")\n",
    "display(df_top_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a718ad6b",
   "metadata": {},
   "source": [
    "### üé≠ View: Distribui√ß√£o por G√™nero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b875435",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM v_genre_distribution\n",
    "ORDER BY total_movies DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df_genres = pd.read_sql(query, engine)\n",
    "print(\"üé≠ Top 10 G√™neros Mais Populares:\\n\")\n",
    "display(df_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09163549",
   "metadata": {},
   "source": [
    "### üìÖ View: Melhores Filmes por Ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106cf2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM v_top_movies_by_year\n",
    "WHERE release_year >= 2010\n",
    "ORDER BY release_year DESC, user_avg_rating DESC\n",
    "LIMIT 15\n",
    "\"\"\"\n",
    "\n",
    "df_top_by_year = pd.read_sql(query, engine)\n",
    "print(\"üìÖ Melhores Filmes por Ano (2010+):\\n\")\n",
    "display(df_top_by_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a918ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ CONCLUS√ÉO\n",
    "\n",
    "### ‚úÖ Objetivos Alcan√ßados:\n",
    "\n",
    "1. **Extra√ß√£o**: Leitura de 4 arquivos CSV (~237K registros)\n",
    "2. **Transforma√ß√£o**: \n",
    "   - Limpeza de IDs inv√°lidos\n",
    "   - Mesclagem de m√∫ltiplos datasets\n",
    "   - Convers√£o de tipos de dados\n",
    "   - Extra√ß√£o de dados JSON complexos\n",
    "   - Normaliza√ß√£o e valida√ß√£o\n",
    "3. **Carga**: Inser√ß√£o de 45K+ filmes e 45K+ avalia√ß√µes no MySQL\n",
    "\n",
    "### üìä Estat√≠sticas Finais:\n",
    "- **Filmes**: 45.433\n",
    "- **Avalia√ß√µes**: 44.989\n",
    "- **Usu√°rios**: 671\n",
    "- **Per√≠odo**: 1995-2016\n",
    "\n",
    "### üöÄ Pr√≥ximos Passos:\n",
    "- Camada GOLD: Star Schema para Data Warehouse\n",
    "- Dashboards no Power BI/Tableau\n",
    "- An√°lises avan√ßadas e Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "**üé¨ Lakehouse pronto para an√°lises!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
