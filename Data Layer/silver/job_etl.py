"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    JOB ETL - RAW para SILVER                                 â•‘
â•‘                  Sistema de AnÃ¡lise de Filmes                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DescriÃ§Ã£o:
    Script de ETL (Extract, Transform, Load) que processa os dados brutos da
    camada RAW e carrega na camada SILVER (banco de dados MySQL).

Funcionalidades:
    1. ExtraÃ§Ã£o dos arquivos CSV da camada RAW
    2. TransformaÃ§Ã£o e limpeza dos dados
    3. Carga no banco de dados MySQL (Silver Layer)

Autor: Sistema de AnÃ¡lise de Filmes
VersÃ£o: 1.0
Data: 2024
"""

import pandas as pd
import ast
import warnings
from sqlalchemy import create_engine, text
from datetime import datetime
import os
import sys

# Suprime warnings desnecessÃ¡rios
warnings.filterwarnings('ignore')


class ETLPipeline:
    """Classe principal do pipeline ETL"""
    
    def __init__(self, db_config, data_path):
        """
        Inicializa o pipeline ETL
        
        Args:
            db_config (dict): ConfiguraÃ§Ãµes de conexÃ£o do banco de dados
            data_path (str): Caminho para a pasta com os arquivos CSV
        """
        self.db_config = db_config
        self.data_path = data_path
        self.engine = None
        self.df_movies = None
        self.df_credits = None
        self.df_keywords = None
        self.df_ratings = None
        self.df_movies_final = None
        
        print("â•" * 80)
        print("ğŸ¬ ETL Pipeline - Sistema de AnÃ¡lise de Filmes")
        print("â•" * 80)
        
    def connect_database(self):
        """Estabelece conexÃ£o com o banco de dados"""
        print("\nğŸ“¡ Conectando ao banco de dados...")
        
        try:
            connection_string = (
                f"mysql+mysqlconnector://{self.db_config['user']}:"
                f"{self.db_config['password']}@{self.db_config['host']}:"
                f"{self.db_config['port']}/{self.db_config['database']}"
            )
            self.engine = create_engine(connection_string)
            
            # Testa a conexÃ£o
            with self.engine.connect() as conn:
                print("âœ… ConexÃ£o estabelecida com sucesso!")
                return True
                
        except Exception as e:
            print(f"âŒ Erro ao conectar ao banco de dados: {e}")
            return False
    
    def extract(self):
        """Extrai dados dos arquivos CSV"""
        print("\n" + "â”€" * 80)
        print("ğŸ“¥ FASE 1: EXTRAÃ‡ÃƒO (Extract)")
        print("â”€" * 80)
        
        try:
            # Carrega movies_metadata.csv
            print("\nğŸ“„ Carregando movies_metadata.csv...")
            movies_path = os.path.join(self.data_path, 'movies_metadata.csv')
            self.df_movies = pd.read_csv(movies_path)
            print(f"   âœ“ {len(self.df_movies):,} filmes carregados")
            
            # Carrega credits.csv
            print("ğŸ“„ Carregando credits.csv...")
            credits_path = os.path.join(self.data_path, 'credits.csv')
            self.df_credits = pd.read_csv(credits_path)
            print(f"   âœ“ {len(self.df_credits):,} registros de crÃ©ditos carregados")
            
            # Carrega keywords.csv
            print("ğŸ“„ Carregando keywords.csv...")
            keywords_path = os.path.join(self.data_path, 'keywords.csv')
            self.df_keywords = pd.read_csv(keywords_path)
            print(f"   âœ“ {len(self.df_keywords):,} registros de palavras-chave carregados")
            
            # Carrega ratings_small.csv
            print("ğŸ“„ Carregando ratings_small.csv...")
            ratings_path = os.path.join(self.data_path, 'ratings_small.csv')
            self.df_ratings = pd.read_csv(ratings_path)
            print(f"   âœ“ {len(self.df_ratings):,} avaliaÃ§Ãµes carregadas")
            
            print("\nâœ… ExtraÃ§Ã£o concluÃ­da com sucesso!")
            return True
            
        except FileNotFoundError as e:
            print(f"\nâŒ Erro: Arquivo nÃ£o encontrado - {e}")
            return False
        except Exception as e:
            print(f"\nâŒ Erro durante a extraÃ§Ã£o: {e}")
            return False
    
    def transform(self):
        """Transforma e limpa os dados"""
        print("\n" + "â”€" * 80)
        print("ğŸ”„ FASE 2: TRANSFORMAÃ‡ÃƒO (Transform)")
        print("â”€" * 80)
        
        # Etapa 1: Limpeza de IDs invÃ¡lidos
        print("\nğŸ§¹ Etapa 1: Limpeza de IDs invÃ¡lidos")
        original_count = len(self.df_movies)
        
        self.df_movies['id'] = pd.to_numeric(self.df_movies['id'], errors='coerce')
        self.df_movies.dropna(subset=['id'], inplace=True)
        self.df_movies['id'] = self.df_movies['id'].astype(int)
        
        removed_count = original_count - len(self.df_movies)
        print(f"   âœ“ {removed_count} registros com ID invÃ¡lido removidos")
        
        # Converte IDs das outras tabelas
        self.df_credits['id'] = self.df_credits['id'].astype(int)
        self.df_keywords['id'] = self.df_keywords['id'].astype(int)
        
        # Etapa 2: Mesclagem dos DataFrames
        print("\nğŸ”— Etapa 2: Mesclagem dos DataFrames")
        self.df_movies = pd.merge(self.df_movies, self.df_credits, on='id', how='left')
        self.df_movies = pd.merge(self.df_movies, self.df_keywords, on='id', how='left')
        print(f"   âœ“ DataFrames mesclados: {self.df_movies.shape}")
        
        # Remove duplicatas
        original_count = len(self.df_movies)
        self.df_movies.drop_duplicates(subset=['id'], keep='first', inplace=True)
        duplicates_removed = original_count - len(self.df_movies)
        print(f"   âœ“ {duplicates_removed} duplicatas removidas")
        
        # Etapa 3: ConversÃ£o de tipos de dados
        print("\nğŸ”¢ Etapa 3: ConversÃ£o de tipos de dados")
        
        self.df_movies['budget'] = pd.to_numeric(
            self.df_movies['budget'], errors='coerce'
        ).fillna(0).astype(int)
        
        self.df_movies['popularity'] = pd.to_numeric(
            self.df_movies['popularity'], errors='coerce'
        ).fillna(0).astype(float)
        
        self.df_movies['release_date'] = pd.to_datetime(
            self.df_movies['release_date'], errors='coerce'
        )
        
        self.df_movies['adult'] = self.df_movies['adult'] == 'True'
        self.df_movies['video'] = self.df_movies['video'] == 'True'
        
        print("   âœ“ Tipos de dados convertidos")
        
        # Etapa 4: ExtraÃ§Ã£o de dados JSON
        print("\nğŸ“¦ Etapa 4: ExtraÃ§Ã£o de dados JSON")
        
        self.df_movies['genres'] = self.df_movies['genres'].apply(
            lambda x: self._extract_json_data(x, 'name')
        )
        
        self.df_movies['cast'] = self.df_movies['cast'].apply(
            lambda x: self._extract_json_data(x, 'name', limit=3)
        )
        
        self.df_movies['keywords'] = self.df_movies['keywords'].apply(
            lambda x: self._extract_json_data(x, 'name')
        )
        
        self.df_movies['director'] = self.df_movies['crew'].apply(
            self._get_director
        )
        
        self.df_movies['belongs_to_collection'] = self.df_movies['belongs_to_collection'].apply(
            self._get_collection_name
        )
        
        self.df_movies['production_companies'] = self.df_movies['production_companies'].apply(
            lambda x: self._extract_json_data(x, 'name', limit=3)
        )
        
        self.df_movies['production_countries'] = self.df_movies['production_countries'].apply(
            lambda x: self._extract_json_data(x, 'name')
        )
        
        self.df_movies['spoken_languages'] = self.df_movies['spoken_languages'].apply(
            lambda x: self._extract_json_data(x, 'name')
        )
        
        print("   âœ“ Dados JSON extraÃ­dos e processados")
        
        # Etapa 5: SeleÃ§Ã£o e preparaÃ§Ã£o final
        print("\nâœ‚ï¸ Etapa 5: SeleÃ§Ã£o de colunas finais")
        
        colunas_finais = [
            'id', 'title', 'overview', 'release_date', 'budget', 'revenue', 'runtime',
            'popularity', 'status', 'tagline', 'vote_average', 'vote_count', 'imdb_id',
            'original_language', 'genres', 'production_companies', 'production_countries',
            'spoken_languages', 'belongs_to_collection'
        ]
        
        self.df_movies_final = self.df_movies[colunas_finais].copy()
        
        # Preenche valores nulos de strings com string vazia
        for col in self.df_movies_final.select_dtypes(include='object').columns:
            self.df_movies_final[col] = self.df_movies_final[col].fillna('')
        
        print(f"   âœ“ DataFrame final preparado: {self.df_movies_final.shape}")
        
        # TransformaÃ§Ã£o da tabela RATINGS
        print("\nğŸŒŸ Etapa 6: TransformaÃ§Ã£o da tabela RATINGS")
        
        self.df_ratings.rename(columns={
            'userId': 'user_id',
            'movieId': 'movie_id',
            'timestamp': 'rating_timestamp'
        }, inplace=True)
        
        self.df_ratings['rating_timestamp'] = pd.to_datetime(
            self.df_ratings['rating_timestamp'], unit='s'
        )
        
        # Filtra apenas avaliaÃ§Ãµes de filmes que existem na base
        valid_movie_ids = self.df_movies_final['id'].unique()
        original_ratings = len(self.df_ratings)
        self.df_ratings = self.df_ratings[self.df_ratings['movie_id'].isin(valid_movie_ids)]
        filtered_ratings = original_ratings - len(self.df_ratings)
        
        print(f"   âœ“ {filtered_ratings} avaliaÃ§Ãµes de filmes inexistentes removidas")
        print(f"   âœ“ {len(self.df_ratings):,} avaliaÃ§Ãµes vÃ¡lidas")
        
        print("\nâœ… TransformaÃ§Ã£o concluÃ­da com sucesso!")
        return True
    
    def load(self):
        """Carrega dados no banco de dados"""
        print("\n" + "â”€" * 80)
        print("ğŸ“¤ FASE 3: CARGA (Load)")
        print("â”€" * 80)
        
        try:
            # Limpa as tabelas antes de carregar
            print("\nğŸ§¹ Limpando tabelas existentes...")
            with self.engine.connect() as connection:
                with connection.begin():
                    connection.execute(text("SET FOREIGN_KEY_CHECKS = 0;"))
                    connection.execute(text("TRUNCATE TABLE ratings;"))
                    connection.execute(text("TRUNCATE TABLE movies;"))
                    connection.execute(text("SET FOREIGN_KEY_CHECKS = 1;"))
            print("   âœ“ Tabelas limpas")
            
            # Carrega tabela MOVIES
            print("\nğŸ“¥ Carregando tabela MOVIES...")
            self.df_movies_final.to_sql(
                'movies',
                con=self.engine,
                if_exists='append',
                index=False,
                chunksize=1000
            )
            print(f"   âœ“ {len(self.df_movies_final):,} filmes carregados")
            
            # Carrega tabela RATINGS
            print("\nğŸ“¥ Carregando tabela RATINGS...")
            self.df_ratings.to_sql(
                'ratings',
                con=self.engine,
                if_exists='append',
                index=False,
                chunksize=5000
            )
            print(f"   âœ“ {len(self.df_ratings):,} avaliaÃ§Ãµes carregadas")
            
            print("\nâœ… Carga concluÃ­da com sucesso!")
            return True
            
        except Exception as e:
            print(f"\nâŒ Erro durante a carga: {e}")
            return False
    
    def run(self):
        """Executa o pipeline completo de ETL"""
        start_time = datetime.now()
        
        print(f"\nğŸ• InÃ­cio: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # Conecta ao banco
        if not self.connect_database():
            return False
        
        # Executa ETL
        if not self.extract():
            return False
            
        if not self.transform():
            return False
            
        if not self.load():
            return False
        
        # FinalizaÃ§Ã£o
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print("\n" + "â•" * 80)
        print("âœ… PIPELINE ETL CONCLUÃDO COM SUCESSO!")
        print("â•" * 80)
        print(f"ğŸ• TÃ©rmino: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"â±ï¸  DuraÃ§Ã£o: {duration:.2f} segundos")
        print(f"ğŸ“Š Resumo:")
        print(f"   â€¢ Filmes carregados: {len(self.df_movies_final):,}")
        print(f"   â€¢ AvaliaÃ§Ãµes carregadas: {len(self.df_ratings):,}")
        print(f"   â€¢ UsuÃ¡rios Ãºnicos: {self.df_ratings['user_id'].nunique():,}")
        print("â•" * 80)
        
        return True
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ©todos auxiliares
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    @staticmethod
    def _extract_json_data(data, key_to_extract, limit=None):
        """Extrai dados de strings JSON"""
        if isinstance(data, str) and data.startswith('['):
            try:
                list_of_items = ast.literal_eval(data)
                if list_of_items:
                    if limit:
                        list_of_items = list_of_items[:limit]
                    names = [item.get(key_to_extract, '') for item in list_of_items]
                    return ', '.join(filter(None, names))
            except (ValueError, SyntaxError):
                return ''
        return ''
    
    @staticmethod
    def _get_director(crew_data):
        """Extrai o nome do diretor da crew"""
        if isinstance(crew_data, str) and crew_data.startswith('['):
            try:
                crew_list = ast.literal_eval(crew_data)
                for member in crew_list:
                    if member.get('job') == 'Director':
                        return member.get('name', '')
            except (ValueError, SyntaxError):
                return ''
        return ''
    
    @staticmethod
    def _get_collection_name(data):
        """Extrai o nome da coleÃ§Ã£o"""
        if isinstance(data, str) and data.startswith('{'):
            try:
                collection_dict = ast.literal_eval(data)
                return collection_dict.get('name', '')
            except (ValueError, SyntaxError):
                return ''
        return ''


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXECUÃ‡ÃƒO PRINCIPAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    # ConfiguraÃ§Ãµes do banco de dados
    DB_CONFIG = {
        'user': 'app_user',
        'password': 'app_password',
        'host': 'db',  # Nome do serviÃ§o no docker-compose
        'port': '3306',
        'database': 'movies_db'
    }
    
    # Caminho dos dados brutos
    DATA_PATH = '/app/data/raw/dados_brutos'
    
    # Cria e executa o pipeline
    try:
        pipeline = ETLPipeline(DB_CONFIG, DATA_PATH)
        success = pipeline.run()
        
        # Retorna cÃ³digo de saÃ­da apropriado
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Pipeline interrompido pelo usuÃ¡rio")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ Erro fatal: {e}")
        sys.exit(1)
